D. Максимизируя всеобщее счастье
Ограничение времени	2 секунды
Ограничение памяти	64Mb
Ввод	стандартный ввод или input.txt
Вывод	стандартный вывод или output.txt
Успешно пройдя все этапы отбора, Кеша осуществил свою заветную мечту и попал на стажировку в свою любимую IT компанию. Так как Кеша отлично показал себя при прохождении секций, руководитель доверил ему сложную исследовательскую задачу: с помощью машинного обучения решить важную проблему бизнеса - повышение счастья новых пользователей сервиса, который развивает команда Кеши. Дело в том, что система хорошо работает для пользователей, которые имеют некоторый опыт взаимодействия с сервисом, однако новые пользователи испытывают ряд неудобств.

Желая сделать этот мир лучше, наш герой с головой погрузился в продуктовую составляющую задачи, сформулировал ее в терминах машинного обучения и довольно быстро смог построить пайплайн для обучения моделей. Дело за малым: осталось внедрить модель в систему real time обработки запросов и вырастить самую главную метрику - счастье пользователей сервиса. Однако, разработчик, который должен был помогать Кеше дотаскивать необходимые для его модели признаки до обработчика запросов, внезапно заболел. Так как Кеша очень ответственный и ему не терпится внедрить свою модель, он нашел временный выход из ситуации - попробовать в качестве прогноза использовать модель без фичей, то есть выдающую на все запросы константный прогноз.

Единственная трудность заключается в том, что показатель "счастье пользователей", за улучшение которого борется Кеша, является сложноизмеримой величиной, которую пока никто не смог записать в виде простой аналитической формулы. Как вдумчивый исследователь, Кеша хочет попробовать несколько разных метрик качества, для каждой из них получить оптимальное значение константы и затем промерить полученные константы в онлайн эксперименте, дабы определить, какая из них лучше растит счастье.

Перед выкаткой в онлайн эксперимент, Кеша обратился к вам, как к своему потенциальному коллеге, чтобы вы помогли ему провалидировать результаты. Помогите Кеше максимизировать всеобщее счастье!

Для вашего удобства Кеша уже сделал предварительную обработку данных и подготовил обучающую выборку. Решается задача регрессии, в которой целевая функция имеет вид , где ai и bi - некоторые статистики, влияющие на счастье пользователя. Кеша знаком с техникой перевзвешивания и активно ее использует для решения задачи: каждому объекту обучающей выборки приписывается некоторый вес, который отвечает за "важность" данного объекта (чем больше вес, тем сильнее модель при обучении штрафуется за отклонение предсказания от значения целевой функции на данном объекте). При целевой переменной указанного вида зачастую бывает разумно для повышения устойчивости модели в качестве веса использовать wi = bi, что и делает Кеша. Таким образом, обучающая выборка - это набор из n объектов, представляющих собой тройки (xi, ai, bi), где xi - признаковое описание объекта, то есть вектор вещественных чисел длиной k (важно помнить, что признаки не будут использоваться при применении в продакшене), ai и bi - статистики, необходимые для вычисления целевой функции ti и веса wi.

Пусть p - прогноз модели, которую обучает Кеша. Тогда используемые в нашей задаче метрики качества можно записать следующим образом:

1. Mean squared error


2. Mean squared logarithmic error


3. Logistic loss


Для использования данной метрики необходимо, чтобы ti ∈ (0, 1), pi ∈ (0, 1) (i = 1, 2, ..., n). Однако в задаче, которую решает Кеша, могут возникать довольно большие значения целевой функции, а следовательно, и предсказаний. Поэтому в формуле присутствует C - некоторая "достаточно большая" константа, отвечающая за нормировку значений ti и pi.

Для каждой из представленных метрик вам необходимо найти оптимальный константный прогноз, максимизирующий счастье пользователей в соответствии с этой метрикой. То есть требуется найти три (по одной для каждой из метрик MSE, MSLE, LogLoss) константы, при которых значения соответствующих метрик будут минимальны на обучающей выборке.

Формат ввода
В первой строке через пробел задаются два целых числа: число объектов обучающей выборки n (1 ≤ n ≤ 1000) и размерность векторов признаковых описаний объектов обучающей выборки k (1 ≤ k ≤ 100).

Следующие n строк содержат k + 2 вещественных чисел, разделенных пробелами:

первые k чисел представляют собой признаковое описание объекта (-1000 ≤ xj ≤ 1000, j = 1, 2, ..., k);
затем статистики a и b (0 < a, b ≤ 1000), необходимые для вычисления весов и таргетов.
Формат вывода
Выведите три оптимальные константы (для метрик MSE, MSLE и LogLoss) с точностью ровно 6 знаков после запятой в одной строке через пробел.

Пример
Ввод	
5 1
5.66192 6.322711 121.257938
3.049585 5.285749 46.892782
0.227632 4.771393 9.516171
145.759519 5.320249 28.646039
22.774692 13.604903 36.033962

Вывод
0.14568 0.138623 0.14568